# The-King-Avatar-LLM
å…¨èŒé«˜æ‰‹robot åŸºäº InternLM å®ç°,æ„Ÿè°¢[Tutorial](https://github.com/InternLM/Tutorial)

[![Static Badge](https://img.shields.io/badge/license-Apache%202.0-00a2a8)][license-url] | [![Static Badge](https://img.shields.io/badge/openxlab-models-blue)][OpenXLab_Model-url] | [![Static Badge](https://img.shields.io/badge/modelscope-models-9371ab)][ModelScope-url]

[license-url]: ./LICENSE
[OpenXLab_Model-url]: https://openxlab.org.cn/models/detail/hoo01/chat-huyu-ABao
[ModelScope-url]: https://www.modelscope.cn/models/hooo01/chat-huyu-ABao
## ç®€ä»‹

åŸºäºã€Šå…¨èŒé«˜æ‰‹ã€‹å°è¯´åŸæ–‡ï¼Œå¹¶é€šè¿‡å¤§æ¨¡å‹è¿›è¡Œé—®ç­”å¯¹çš„ç”Ÿæˆã€‚
ä½¿ç”¨InternLM2è¿›è¡ŒQLoraå¾®è°ƒ+RAGè¯­æ–™åº“å¾—åˆ°ã€‚

> ç½‘æ¸¸è£è€€ä¸­è¢«èª‰ä¸ºæ•™ç§‘ä¹¦çº§åˆ«çš„é¡¶å°–é«˜æ‰‹å¶ä¿®ï¼Œå› ä¸ºç§ç§åŸå› é­åˆ°ä¿±ä¹éƒ¨çš„é©±é€ï¼Œç¦»å¼€èŒä¸šåœˆçš„ä»–æ –èº«äºä¸€å®¶ç½‘å§æˆäº†ä¸€ä¸ªå°å°çš„ç½‘ç®¡ï¼Œä½†æ˜¯ï¼Œæ‹¥æœ‰åå¹´æ¸¸æˆç»éªŒçš„ä»–ï¼Œåœ¨è£è€€æ–°å¼€çš„ç¬¬ååŒºé‡æ–°æŠ•å…¥äº†æ¸¸æˆï¼Œå¸¦ç€å¾€æ˜”çš„å›å¿†å’Œä¸€æŠŠç”±è‹æ²ç§‹åˆ¶ä½œçš„ã€å´å› æ¸¸æˆç‰ˆæœ¬æ›´æ–°è¢«è¿«æç½®çš„é“¶æ­¦åƒæœºä¼ï¼Œå¼€å§‹äº†é‡è¿”å·…å³°ä¹‹è·¯ã€‚
> åœ¨æ•°å­—åŒ–æ—¶ä»£ï¼Œæ–‡å­¦ä½œå“çš„é˜…è¯»ä¸æ¢ç´¢æ­£é€æ­¥è¿ˆå‘æ™ºèƒ½åŒ–çš„æ–°é«˜åº¦ã€‚æœ¬é¡¹ç›®æ—¨åœ¨æ­å»ºä¸€ä¸ªåˆ›æ–°æ€§çš„å¹³å°ï¼Œè¯¥å¹³å°æ ¸å¿ƒåŠŸèƒ½æ˜¯å°†ç»å…¸åŠåŸåˆ›å°è¯´å†…å®¹å…¨é¢èå…¥å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†åº“ä¸­ï¼Œé€šè¿‡å®ç°åŸºäº Retrieval-Augmented Generation (RAG) çš„é—®ç­”ç³»ç»Ÿï¼Œä¸ºç”¨æˆ·æä¾›å‰æ‰€æœªæœ‰çš„äº’åŠ¨é˜…è¯»ä½“éªŒã€‚

## æ¶æ„å›¾
![enter image description here](./asset/Architecture.png?raw=true)

## è®²è§£è§†é¢‘
[å¾®è°ƒInternLMå¤§æ¨¡å‹ï¼Œæ¥äº†è§£ã€Šå…¨èŒé«˜æ‰‹ã€‹å§ï¼](https://www.bilibili.com/video/BV1dYaoebERQ/?vd_source=6856ef3925c77e098a1a2df5b9634513#reply112908180655895)

## é¡¹ç›®äº®ç‚¹

 1. å¯ä½¿ç”¨è¯­éŸ³è¿›è¡Œæ’­æŠ¥

 2. å°è¯´å†…å®¹ä¸Šç­‰é—®é¢˜å›ç­”è¡¨ç°è‰¯å¥½

## å¾…æ·»åŠ åŠŸèƒ½

- å›¾ç”Ÿæ–‡ğŸ’¬
- æ”¯æŒ ASR è¯­éŸ³è¾“å…¥ ğŸ™ï¸
- æ”¯æŒç‰¹å®šæƒ…å¢ƒä¸‹çš„å£è¯­å¯¹è¯ğŸ“
- æ”¯æŒç”Ÿæˆæ•°å­—äººè§†é¢‘ğŸ¦¸
- éƒ¨ç½²é›†æˆ LMDeploy åŠ é€Ÿæ¨ç†ğŸš€

## å¿«é€Ÿå¼€å§‹

â• æš‚æ—¶ä»…æä¾›æœ¬åœ°éƒ¨ç½²æ–¹æ³•ï¼Œå»ºè®®ä½¿ç”¨30%ä»¥ä¸Šçš„A100ã€cuda11.7çš„é…ç½®è¿è¡Œ

**1.clone æœ¬é¡¹ç›®è‡³æœ¬åœ°å¼€å‘æœº** 

    git clone https://github.com/shiqiyio/The-King-Avatar-LLM.git

**2.é…ç½®ç¯å¢ƒ**

    #åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
    conda create -n quanzhi python=3.10 
    # æ¿€æ´»ç¯å¢ƒ 
    conda activate quanzhi
    # å®‰è£…æ‰€éœ€ä¾èµ–ï¼ˆè¿™ä¸€æ­¥æ‰€éœ€æ—¶é—´è¾ƒé•¿ï¼‰
    cd The-King-Avatar-LLM
    pip install -r requirements.txt

**3.ç”ŸæˆRAGä¾èµ–çš„Chromaæ•°æ®åº“**

    python gen_chroma.py

**4.å¯åŠ¨(æ­¤éƒ¨åˆ†å› ä¸‹è½½æ¨¡å‹éœ€è¦è¾ƒé•¿æ—¶é—´)**

    python start.py

> é»˜è®¤ç«¯å£å’Œipä¸º127.0.0.1:7860ï¼Œå¦‚éœ€å˜æ›´è¯·æ‰“å¼€start.pyä¿®æ”¹<br>
> æ¨èé€šè¿‡vscodeè¿›è¡Œç«¯å£æ˜ å°„ï¼Œæ–¹ä¾¿å¿«æ·ï¼<br>
>
> qlora å¾®è°ƒè¿‡ç¨‹![image-20240803001645804](https://github.com/shiqiyio/The-King-Avatar-LLM/blob/main/asset/process.png)

**5.ç¤ºä¾‹æ•ˆæœ**

![image-20240804235145720](./asset/display.png)

## å¾®è°ƒæ€è·¯
<details>
<summary>ç‚¹å‡»å±•å¼€è¯¦ç»†æ€è·¯</summary>

**1.æ•°æ®å‡†å¤‡**<br>
æ•°æ®ï¼šã€Šå…¨èŒé«˜æ‰‹ã€‹å°è¯´<br>

1.ä½¿ç”¨qwen2_7Bç”Ÿæˆé—®ç­”å¯¹<br>
ä½¿ç”¨æœ¬åœ°qwen_7Bå¤§æ¨¡å‹ï¼Œæä¾›promptï¼Œæ‰¹é‡ç”Ÿæˆé—®é¢˜ï¼ŒåŒæ—¶ä¼ å…¥æ‰€ç”Ÿæˆçš„é—®é¢˜ï¼Œå¹¶è¿›è¡Œå›ç­”ã€‚<br>
å®Œæ•´è„šæœ¬è§scriptsç›®å½•<br>

2.ä½¿ç”¨è„šæœ¬å°†ä»¥ä¸Šæ–‡æœ¬é—®ç­”å¯¹ï¼Œè½¬æ¢ä¸ºæ¨¡å‹å¾®è°ƒæ‰€éœ€è¦çš„ç±»å‹ã€‚<br>
å®Œæ•´è„šæœ¬è§scriptsç›®å½•<br>

é€šè¿‡ä»¥ä¸Šæ­¥éª¤å¾—åˆ°ç¬¦åˆxtunerå¾®è°ƒæ ¼å¼çš„jsonlæ•°æ®ã€‚<br>

**2.å¾®è°ƒæ¨¡å‹**<br>
xtunerå¾®è°ƒå·¥å…·åŒ…çš„å®˜æ–¹æ•™ç¨‹ï¼š  <br>
https://github.com/InternLM/Tutorial/blob/camp2/xtuner/personal_assistant_document.md
https://github.com/InternLM/Tutorial/blob/camp2/data_fine_tuning/data_fine_tuning.md<br>
1.é€‰æ‹©åŸºåº§æ¨¡å‹<br>
åŸºåº§æ¨¡å‹é€‰æ‹©äº†internlm2-chat-7bã€‚<br>
2.é…ç½®æ–‡ä»¶ä¿®æ”¹<br>
æŒ‰ç…§æ•™ç¨‹é‡Œçš„é…ç½®æ–‡ä»¶ï¼Œå¯¹PART1ä¿®æ”¹ï¼Œå…¶ä½™éƒ¨åˆ†æœªåŠ¨ï¼š<br>
part1æ”¹åŠ¨ï¼š

     # Model
    pretrained_model_name_or_path = './model'#ä¿®æ”¹ä¸ºåŸºåº§æ¨¡å‹çš„è·¯å¾„
    use_varlen_attn = False
    # Data
    alpaca_en_path = './data/novel.json'#ä¿®æ”¹åŸå§‹æ•°æ®é›†è·¯å¾„
    prompt_template = PROMPT_TEMPLATE.internlm2_chat#æ ¹æ®åŸºåº§æ¨¡å‹é€‰æ‹©ç›¸åº”çš„æ¨¡ç‰ˆ
    max_length = 2048
    pack_to_max_length = True
    # parallel
    sequence_parallel_size = 1
    # Scheduler & Optimizer
    batch_size = 1  # per_device
    accumulative_counts = 8
    accumulative_counts *= sequence_parallel_size
    dataloader_num_workers = 0
    max_epochs = 5
    optim_type = AdamW
    lr = 1e-4
    betas = (0.9, 0.999)
    weight_decay = 0
    max_norm = 1  # grad clip
    warmup_ratio = 0.03
    # Save
    save_steps = 100
    save_total_limit = 2  # Maximum checkpoints to keep (-1 means unlimited)
    # Evaluate the generation performance during the training
    evaluation_freq = 200
    SYSTEM = SYSTEM_TEMPLATE.alpaca
    evaluation_inputs = [
    '"ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼Ÿ', 'åƒæœºä¼æœ‰å“ªäº›å½¢æ€ï¼Ÿ'
    ]
3.ç»§ç»­è®­ç»ƒ<br>
åœ¨åˆæ­¥è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹çš„é—®ç­”å°šæœªè¾¾åˆ°é¢„æœŸæ•ˆæœã€‚é‡‡å»ç»­è®­çš„æ–¹å¼ï¼Œå°†`Resume=True`ã€‚å°†åˆæ¬¡è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹ä½œä¸ºé¢„è®­ç»ƒæ¨¡å‹ï¼ˆpretrained_modelï¼‰ï¼Œè¿›è¡Œç»§ç»­è®­ç»ƒï¼Œä»è€Œå®ç°å¯¹æ•°æ®é›†æ›´å¥½çš„ç†è§£åŠé—®ç­”è¾“å‡ºçš„æ›´å¥½ã€‚<br>
4.å±€é™<br>
å¾®è°ƒåçš„æ¨¡å‹åŸºæœ¬ä¸Šå¯ä»¥åº”å¯¹æ—¥å¸¸çš„ï¼Œä½†å¯¹å°è¯´çš„å‰§æƒ…å’Œäººç‰©å…³ç³»ç†è§£æ–¹é¢ï¼Œå…¶è¡¨ç°ä»æœ‰å¾…æå‡ã€‚å¯¹æ­¤ï¼Œå¼•å…¥RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯ã€‚é€šè¿‡æ£€ç´¢çŸ¥è¯†åº“ä¿¡æ¯ï¼Œè¾…åŠ©æ¨¡å‹æ›´å‡†ç¡®åœ°å›ç­”å°è¯´çš„æƒ…èŠ‚å’Œäººç‰©å…³ç³»é—®é¢˜ã€‚

**3.RAGæ£€ç´¢å¢å¼º**<br>
RAGè®¾è®¡é“¾è·¯å‚è€ƒï¼š<br>
[https://github.com/InternLM/tutorial/tree/camp1/langchain](https://github.com/InternLM/tutorial/tree/camp1/langchain)
[https://github.com/datawhalechina/llm-universe/tree/main/notebook](https://github.com/datawhalechina/llm-universe/tree/main/notebook)<br>
1.çŸ¥è¯†åº“æ­å»º<br>å°†å°è¯´txtæ–‡ä»¶ä½œä¸ºè¯­æ–™åº“ã€‚<br>
2.æ„å»ºå‘é‡æ•°æ®åº“<br>
å®Œæ•´è„šæœ¬è§gen_chroma.py<br>
å…¶ä¸­<br>

> chunk_sizeçš„å¤§å°è¦èƒ½åŒ…å«ä¸€ä¸ªå®Œæ•´çš„conversationï¼› å› ä¸ºæ˜¯é•¿æ–‡æœ¬txtï¼Œåˆ†å‰²é€‰æ‹©é€’å½’åˆ†å‰²ï¼›<br>
> ç»è¿‡æµ‹è¯•å¬å›æ–‡æ¡£çš„æ•ˆæœï¼Œè¯å‘é‡æ¨¡å‹æœ€ç»ˆé€‰æ‹©çš„æ˜¯shibing624/text2vec-base-chineseï¼Œä½¿ç”¨huggingfaceå¯¼å…¥ï¼›<br>
> ä½¿ç”¨chromaä½œä¸ºå‘é‡æ•°æ®åº“ï¼Œè¿è¡Œå³å¯å¾—åˆ°æŒä¹…åŒ–çš„å‘é‡æ•°æ®åº“ï¼Œæ— éœ€é‡å¤æ„å»ºã€‚
> 
> `#åˆ›å»ºæ–‡æœ¬åˆ†å‰²å™¨å®ä¾‹` `text_splitter =
> RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)`
> `embedding_function =
> HuggingFaceEmbeddings(model_name="shibing624/text2vec-base-chinese")`
> `persist_directory ='/root/thisis/chroma'#æ ¹æ®ä¸‹è½½æ¨¡å‹çš„è·¯å¾„è°ƒæ•´ï¼Œå»ºè®®å†™ç»å¯¹è·¯å¾„`

3.æ¥å…¥LangChainæ¡†æ¶<br>
å®Œæ•´è„šæœ¬è§llm.py<br>
4.æ„å»ºæ£€ç´¢é—®ç­”é“¾<br>
å®Œæ•´è„šæœ¬è§ragchat.py<br>
åœ¨prompt templateå¼•å¯¼æ¨¡å‹ä½¿ç”¨å¤–éƒ¨å¢å¼ºçš„çŸ¥è¯†åº“

        template = """
        **Context**ï¼ˆèƒŒæ™¯ï¼‰ï¼š
        ä½ æ˜¯ä¸€ä¸ªç”±åä¸ƒä¸“é—¨è®­ç»ƒçš„ã€Šå…¨èŒé«˜æ‰‹ã€‹å°è¯´é—®ç­”æ¨¡å‹ã€‚å¯ä»¥æä¾›å‡†ç¡®ä¸”è¯¦ç»†çš„è§£ç­”ï¼Œå¸®åŠ©ç”¨æˆ·æ·±å…¥äº†è§£è¿™éƒ¨å°è¯´çš„è§’è‰²ã€æƒ…èŠ‚å’ŒèƒŒæ™¯ã€‚
        
        **Objective**ï¼ˆç›®æ ‡ï¼‰ï¼š
        å›ç­”æœ‰å…³ã€Šå…¨èŒé«˜æ‰‹ã€‹çš„é—®é¢˜ï¼Œæä¾›æœ‰ä»·å€¼çš„è§è§£ï¼Œå¹¶ç¡®ä¿å›ç­”åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        
        **Structure**ï¼ˆç»“æ„ï¼‰ï¼š
        1. ç†è§£é—®é¢˜åŠå…¶èƒŒæ™¯ã€‚
        2. æŸ¥é˜…æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
        3. ä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ä¼˜å…ˆå›ç­”é—®é¢˜ã€‚
        4. å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œå†ä½¿ç”¨æ¨¡å‹çš„é€šç”¨çŸ¥è¯†ã€‚
        
        **Task**ï¼ˆä»»åŠ¡ï¼‰ï¼š
        å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œç¡®ä¿å›ç­”åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¹¶åœ¨å¿…è¦æ—¶å‚è€ƒå…¶ä»–çŸ¥è¯†ã€‚
        
        **Action**ï¼ˆè¡ŒåŠ¨ï¼‰ï¼š
        è¯¦ç»†é˜…è¯»é—®é¢˜ï¼Œå¹¶ç»“åˆä¸Šä¸‹æ–‡ä¿¡æ¯æä¾›å‡†ç¡®çš„å›ç­”ã€‚
        
        **Result**ï¼ˆç»“æœï¼‰ï¼š
        æä¾›ä¸€ä¸ªè¯¦ç»†ã€å‡†ç¡®ä¸”åŸºäºä¸Šä¸‹æ–‡çš„ä¿¡æ¯ï¼Œä»¥è§£ç­”é—®é¢˜å¹¶æ»¡è¶³ç”¨æˆ·çš„éœ€æ±‚ã€‚
        
        é—®é¢˜: {question}
        
        ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
        Â·Â·Â·
        {context}
        Â·Â·Â·
        
        è¯·æ ¹æ®ä¸Šè¿°æ¡†æ¶å›ç­”é—®é¢˜ã€‚
    """

5.æ¥å…¥streamlit<br>
è§app.pyå’Œstart.py<br>
</details> 

## è‡´è°¢

 - [ä¹¦ç”Ÿæµ¦è¯­](https://internlm.intern-ai.org.cn/)æä¾›çš„å¹³å°åŠç®—åŠ›èµ„æº<br>
æ¬¢è¿å¤§å®¶æŠ¥åæ–°ä¸€æœŸçš„ä¹¦ç”Ÿæµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥ï¼[ç¬¬ä¸‰æœŸæŠ¥å](https://github.com/InternLM/Tutorial)
 - [chat-æ²ªè¯­-é˜¿å®](https://github.com/hoo01/chat-huyu-ABao)

