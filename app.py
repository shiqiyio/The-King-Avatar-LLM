import streamlit as st
from ragchat import Model_center
from llm import InternLM
from tts import text_to_speech
import os

def on_btn_click():
    del st.session_state.messages
    # del st.session_state.audio_file

def on_btn_click_tts(response):
    try:
        # è½¬æ¢æ–‡æœ¬ä¸ºè¯­éŸ³
        print("å‡†å¤‡è½¬æ¢ä¸ºéŸ³é¢‘...")
        text_to_speech(response)
        
        audio_file = './data/result.mp3'
        if os.path.exists(audio_file):
            st.session_state.audio_file = audio_file  # å°†éŸ³é¢‘æ–‡ä»¶è·¯å¾„å­˜å‚¨åœ¨ä¼šè¯çŠ¶æ€ä¸­
        else:
            st.error("éŸ³é¢‘æ–‡ä»¶æœªç”Ÿæˆæˆ–è·¯å¾„é”™è¯¯")
    except Exception as e:
        st.error(f"å¤„ç†è¯­éŸ³æ—¶å‘ç”Ÿé”™è¯¯: {e}")

@st.cache_resource
def load_model(model_name_or_path):
    llm = InternLM(model_path=model_name_or_path)
    model_center = Model_center(llm)
    return model_center

model_name_or_path = './quanzhigaoshou'

if not os.path.exists(model_name_or_path):

    os.system('apt install git')
    os.system('apt install git-lfs')
    os.system(f'git clone https://code.openxlab.org.cn/shiqiyioo/quanzhigaoshou.git {model_name_or_path}')
    os.system(f'cd {model_name_or_path} && git lfs pull')
    print("æ¨¡å‹ä¸‹è½½å®Œæˆ")

# model_name_or_path = '/root/share/model_repos/internlm-chat-7b'
model_center = load_model(model_name_or_path)

if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "audio_file" not in st.session_state:
    st.session_state.audio_file = None

with st.sidebar:
    st.markdown("The-King-Avatar-LLM")
    st.markdown("[InternLM](https://github.com/InternLM/InternLM.git)")
    st.markdown("[chat-huyu-ABao](https://github.com/shiqiyio/The-King-Avatar-LLM)")
    st.markdown("æ„Ÿè°¢[chat-huyu-ABao](https://github.com/hoo01/chat-huyu-ABao.git)")
    st.button('Clear Chat History', on_click=on_btn_click)

st.title("The-King-Avatar-LLM")
st.caption("ğŸš€ ä¸€ä¸ªç”± InternLM2_7B QLora æ”¯æŒçš„ Streamlit èŠå¤©æœºå™¨äºº")

for msg in st.session_state.messages:
    st.chat_message("user").write(msg["user"])
    st.chat_message("assistant").write(msg["assistant"])

if prompt := st.chat_input("æå‡ºä»»ä½•å…³äºã€Šå…¨èŒé«˜æ‰‹ã€‹çš„é—®é¢˜"):
    st.chat_message("user").write(prompt)
    response = model_center.qa_chain_self_answer(prompt)
    st.session_state.messages.append({"user": prompt, "assistant": response}) 
    st.chat_message("assistant").write(response)

    # åœ¨å“åº”ä¸‹æ–¹æ·»åŠ  TTS æŒ‰é’®
    st.button("è¯­éŸ³æ’­æ”¾", on_click=on_btn_click_tts, args=(response,))

# å¦‚æœéŸ³é¢‘æ–‡ä»¶å­˜åœ¨ï¼Œåˆ™æ˜¾ç¤ºéŸ³é¢‘æ’­æ”¾å™¨
if st.session_state.audio_file:
    st.audio(st.session_state.audio_file, format='audio/mp3')
del st.session_state.audio_file
